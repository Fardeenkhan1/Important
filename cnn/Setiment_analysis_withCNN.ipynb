{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b927cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, preprocessing\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b87fdf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "n_words = 10000\n",
    "dim_embedding = 256\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE =500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e0cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.imdb.load_data(num_words=n_words)\n",
    "    X_train = preprocessing.sequence.pad_sequences(X_train, maxlen = max_len)\n",
    "    X_test = preprocessing.sequence.pad_sequences(X_test, maxlen = max_len)\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4ece26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    # Input - Embedding Layer\n",
    "    # the model will take as input an integer matrix of size\n",
    "    # (batch, input_length)\n",
    "    # the model will output dimension (input_length, dim_embedding)\n",
    "    # the largest integer in the input should be no larger\n",
    "    # than n_words (vocabulary size).\n",
    "    model.add(layers.Embedding(n_words,dim_embedding, input_length=max_len))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv1D(256, 3, padding='valid',\n",
    "    activation='relu'))\n",
    "    # takes the maximum value of either feature vector from each of\n",
    "    # the n_words features\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95f8f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\Asad\\anaconda4\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\Asad\\anaconda4\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 256)          2560000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 198, 256)          196864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,789,889\n",
      "Trainable params: 2,789,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "model=build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92edff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb39d31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50/50 [==============================] - 31s 609ms/step - loss: 0.6488 - accuracy: 0.6299 - val_loss: 0.5055 - val_accuracy: 0.7719\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 30s 608ms/step - loss: 0.3838 - accuracy: 0.8317 - val_loss: 0.2994 - val_accuracy: 0.8746\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 30s 605ms/step - loss: 0.2424 - accuracy: 0.9044 - val_loss: 0.2635 - val_accuracy: 0.8896\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 30s 607ms/step - loss: 0.1575 - accuracy: 0.9453 - val_loss: 0.2685 - val_accuracy: 0.8892\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 30s 606ms/step - loss: 0.0947 - accuracy: 0.9726 - val_loss: 0.2908 - val_accuracy: 0.8888\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 30s 605ms/step - loss: 0.0489 - accuracy: 0.9886 - val_loss: 0.3215 - val_accuracy: 0.8860\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 30s 600ms/step - loss: 0.0260 - accuracy: 0.9950 - val_loss: 0.3604 - val_accuracy: 0.8867\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 30s 605ms/step - loss: 0.0138 - accuracy: 0.9980 - val_loss: 0.3938 - val_accuracy: 0.8852\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 30s 602ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.4281 - val_accuracy: 0.8842\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 30s 598ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.4537 - val_accuracy: 0.8839\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 30s 612ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.4704 - val_accuracy: 0.8826\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 31s 613ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.4881 - val_accuracy: 0.8835\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 31s 613ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.8833\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 31s 619ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.5219 - val_accuracy: 0.8822\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 31s 622ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.5348 - val_accuracy: 0.8812\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 31s 621ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5449 - val_accuracy: 0.8832\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 32s 637ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.5593 - val_accuracy: 0.8820\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 33s 656ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.5684 - val_accuracy: 0.8823\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 32s 651ms/step - loss: 8.2457e-04 - accuracy: 0.9999 - val_loss: 0.5830 - val_accuracy: 0.8815\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 30s 607ms/step - loss: 7.7945e-04 - accuracy: 1.0000 - val_loss: 0.5961 - val_accuracy: 0.8804\n"
     ]
    }
   ],
   "source": [
    "score = model.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20c87b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 5s 99ms/step - loss: 0.5961 - accuracy: 0.8804\n",
      "\n",
      "Test score: 0.5960948467254639\n",
      "Test accuracy: 0.8804000020027161\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a28d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
