{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "631a3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fff7d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('C:/Users/Asad/Downloads/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ead0ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnSpecialCharacters(texts,y):\n",
    "    seq = []\n",
    "    for i, text in enumerate(texts):\n",
    "        try:\n",
    "            final = [re.sub(r\"[^a-zA-Z]+\", ' ', k) for k in text.split(\" \")]\n",
    "            seq.append(' '.join(final))\n",
    "        except:\n",
    "            del y[i]\n",
    "#             seq.append('  ')\n",
    "            pass\n",
    "    return seq, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "762c4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data_frame['text']\n",
    "# texts = data_frame['text'].values\n",
    "y = data_frame['is_offensive']\n",
    "texts,y = returnSpecialCharacters(texts,y)\n",
    "y = data_frame['is_offensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b437ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "text_sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c1b0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184350 sentences, max length: 1403\n"
     ]
    }
   ],
   "source": [
    "text_sequences = tf.keras.preprocessing.sequence.pad_sequences(text_sequences)\n",
    "num_records = len(text_sequences)\n",
    "max_seqlen = len(text_sequences[0])\n",
    "\n",
    "print('{:d} sentences, max length: {:d}'.format(num_records, max_seqlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f67cfbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "labels = tf.keras.utils.to_categorical(y, num_classes = NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7853768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size 174765\n"
     ]
    }
   ],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "idx2word = {v:k for k,v in word2idx.items()}\n",
    "word2idx[\"PAD\"] = 0\n",
    "idx2word[0] = \"PAD\"\n",
    "vocab_size = len(word2idx)\n",
    "print('vocab size {:d}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdaa1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((text_sequences, labels))\n",
    "dataset = dataset.shuffle(10000)\n",
    "test_size = num_records//4\n",
    "val_size = (num_records - test_size)//10\n",
    "test_dataset = dataset.take(test_size)\n",
    "val_dataset = dataset.skip(test_size).take(val_size)\n",
    "train_dataset = dataset.skip(test_size + val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fa18a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder = True)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder = True)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32dc029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_MODEL = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92c97b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_matrix(EMBEDDING_MODEL, word2idx, EMBEDDING_DIM):\n",
    "    E = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    for word, idx in word2idx.items():\n",
    "        try:\n",
    "            E[idx] = EMBEDDING_MODEL.word_vec(word)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb75f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "E = build_embedding_matrix(EMBEDDING_MODEL, word2idx, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ca61812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174765, 300)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0483a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamClassifierModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_sz, embed_sz, input_length, num_filters, kernel_sz, output_sz, embedding_weights, **kwargs):\n",
    "        super(SpamClassifierModel, self).__init__(**kwargs)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_sz,embed_sz, input_length = input_length, weights = [embedding_weights],\n",
    "                                                  trainable = False)\n",
    "        self.conv = tf.keras.layers.Conv1D(filters = num_filters, kernel_size = kernel_sz, activation = 'relu')\n",
    "        self.dropout = tf.keras.layers.SpatialDropout1D(0.2)\n",
    "        self.pool = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        self.dense = tf.keras.layers.Dense(output_sz,  activation = 'softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "644d93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 256\n",
    "kernel_sz = 3\n",
    "model = SpamClassifierModel(vocab_size, EMBEDDING_DIM, max_seqlen, filters, kernel_sz, NUM_CLASSES, E)\n",
    "model.build(input_shape = (None, max_seqlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ba53541",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55a49319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    147505\n",
       "1     36845\n",
       "Name: is_offensive, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['is_offensive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6811eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asad\\anaconda4\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/3\n",
      "972/972 [==============================] - 658s 676ms/step - loss: 0.7020 - accuracy: 0.8143 - val_loss: 0.4427 - val_accuracy: 0.8487\n",
      "Epoch 2/3\n",
      "972/972 [==============================] - 652s 670ms/step - loss: 0.5729 - accuracy: 0.8879 - val_loss: 0.3324 - val_accuracy: 0.8890\n",
      "Epoch 3/3\n",
      "972/972 [==============================] - 621s 639ms/step - loss: 0.5279 - accuracy: 0.9012 - val_loss: 0.4176 - val_accuracy: 0.8866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d789e877c0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 3\n",
    "CLASS_WEIGHTS = {0:1, 1:4}\n",
    "\n",
    "model.fit(train_dataset, epochs = NUM_EPOCHS, validation_data = val_dataset, class_weight = CLASS_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a661a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5', save_format= 'h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60f5a8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.884\n",
      "confusion matrix\n",
      "[[32323  4569]\n",
      " [  783  8405]]\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = [], []\n",
    "for Xtest, Ytest in test_dataset:\n",
    "    y_pred = model.predict_on_batch(Xtest)\n",
    "    y_pred = np.argmax(y_pred, axis = 1)\n",
    "    y_test = np.argmax(Ytest, axis = 1)\n",
    "    labels.extend(y_test.tolist())\n",
    "    predictions.extend(y_pred.tolist())\n",
    "\n",
    "print(\"test accuracy: {:.3f}\".format(accuracy_score(labels, predictions)))\n",
    "print(\"confusion matrix\")\n",
    "print(confusion_matrix(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4593bf69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
