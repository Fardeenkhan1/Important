{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a553fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, Dense, Reshape\n",
    "from tensorflow.keras.layers import Flatten, Input, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "w_init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b429a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-contrib-python==3.4.8.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5807e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_H = 64\n",
    "IMG_W = 64 \n",
    "IMG_C = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687127d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(examples, epoch, n):\n",
    "    examples = (examples + 1.0)/2.0\n",
    "    for i in range(n*n):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(examples[i])\n",
    "    filename = f\"results/generated_plot_epoch-{34+epoch+1}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e675b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_png(image)\n",
    "    image = tf.image.resize_with_crop_or_pad(image,IMG_H, IMG_W)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image - 127.5) / 127.5\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03315b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(images_path, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(images_path)\n",
    "    dataset = dataset.shuffle(buffer_size = 10240)\n",
    "    dataset = dataset.map(load_image)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size = 4)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b335c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_block(inputs, num_filters, kernel_size, strides, bn = True):\n",
    "    x = Conv2DTranspose(\n",
    "        filters = num_filters,\n",
    "        kernel_size = kernel_size,\n",
    "        kernel_initializer = w_init,\n",
    "        use_bias = False,\n",
    "        padding = 'same',\n",
    "        strides = strides)(inputs)\n",
    "    if bn:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha = 0.2)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dda4fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters, kernel_size, padding = 'same', strides = 2, activation = True):\n",
    "    x = Conv2D(filters = num_filters,\n",
    "        kernel_size = kernel_size,\n",
    "        kernel_initializer = w_init,\n",
    "        strides = strides,\n",
    "        padding = padding\n",
    "        )(inputs)\n",
    "    \n",
    "    if activation:\n",
    "        x = LeakyReLU(alpha = 0.2)(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e582cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(latent_dim):\n",
    "    f = [16, 8, 4, 2, 1]\n",
    "    filters = 32\n",
    "    output_strides = 16\n",
    "    h_output = IMG_H // output_strides\n",
    "    w_output = IMG_W // output_strides\n",
    "    \n",
    "    noise = Input(shape = (latent_dim, ), name = 'gen_noise_input')\n",
    "    \n",
    "    x = Dense(f[0] * filters * h_output * w_output, use_bias = False)(noise)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha = 0.2)(x)\n",
    "    x = Reshape((h_output, w_output, f[0]*filters))(x)\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        x = deconv_block(x, num_filters = f[i]*filters, kernel_size = 5, strides = 2, bn = True)\n",
    "    \n",
    "    x = conv_block(x, num_filters = 3, kernel_size = 5, strides = 1, activation = False)\n",
    "    \n",
    "    fake = Activation('tanh')(x)\n",
    "    \n",
    "    return Model(noise, fake, name = 'generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dea1b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    f = [16, 8, 4, 2, 1]\n",
    "    filters  = 64\n",
    "    image_Input = Input(shape = (IMG_H, IMG_W, IMG_C))\n",
    "    output_strides = 16\n",
    "    h_output = IMG_H // output_strides\n",
    "    w_output = IMG_W // output_strides\n",
    "    \n",
    "    x = image_Input\n",
    "    for i in reversed(range(1,5)):\n",
    "        x = conv_block(x, filters*f[i], kernel_size = 5, strides = 2)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    \n",
    "    return Model(image_Input, x, name = 'discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0ca15a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "    def train_step(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        \n",
    "        \"\"\"TRAIN DISCRIMINATOR\"\"\"\n",
    "        for _ in range(2):\n",
    "            \"\"\"For Fake Images\"\"\"\n",
    "            random_vectors = tf.random.normal(shape = (batch_size, self.latent_dim))\n",
    "            generated_images = self.generator(random_vectors)\n",
    "            generated_labels = tf.zeros([batch_size, 1])\n",
    "            \n",
    "            with tf.GradientTape() as d1tape:\n",
    "                predictions = self.discriminator(generated_images)\n",
    "                d1_loss = self.loss_fn(generated_labels, predictions)\n",
    "            grads = d1tape.gradient(d1_loss, self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "            \n",
    "            \"\"\"For Real Images\"\"\"\n",
    "            labels = tf.ones([batch_size, 1])\n",
    "            with tf.GradientTape() as d2tape:\n",
    "                predictions = self.discriminator(images)\n",
    "                d2_loss = self.loss_fn(labels, predictions)\n",
    "            grads = d2tape.gradient(d2_loss, self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "            \n",
    "            \n",
    "        \"\"\"TRAINING GENERATOR\"\"\"\n",
    "        random_latent_vectors = tf.random.normal(shape = (batch_size, self.latent_dim))\n",
    "        fake_labels = tf.ones([batch_size, 1])\n",
    "        \n",
    "        with tf.GradientTape() as gtape:\n",
    "            generated_images = self.generator(random_latent_vectors)\n",
    "            predictions = self.discriminator(generated_images)\n",
    "            g_loss = self.loss_fn(fake_labels, predictions)\n",
    "        grads = gtape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        \n",
    "        return {'d1_loss' : d1_loss, 'd2_loss' : d2_loss, 'g_loss' : g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6979651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:  21551\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 4,314,753\n",
      "Trainable params: 4,314,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gen_noise_input (InputLayer) [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8192)              1048576   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 8, 8, 256)         3276800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 128)       819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 32)        51200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 3)         2403      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 64, 3)         0         \n",
      "=================================================================\n",
      "Total params: 5,437,667\n",
      "Trainable params: 5,420,323\n",
      "Non-trainable params: 17,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 128\n",
    "\n",
    "images_path = glob('data/*')\n",
    "print(\"Dataset Size: \", len(images_path))\n",
    "\n",
    "dataset = tf_dataset(images_path, batch_size)\n",
    "\n",
    "d_model = discriminator()\n",
    "g_model = generator(LATENT_DIM)\n",
    "\n",
    "d_model.summary()\n",
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bf5d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits = True, label_smoothing = 0.1)\n",
    "d_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001, beta_1 = 0.5)\n",
    "g_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0002, beta_1 = 0.5)\n",
    "d_model.compile(loss = loss_fn, optimizer = d_optimizer)\n",
    "g_model.compile(loss = loss_fn, optimizer = g_optimizer)\n",
    "gan = GAN(d_model, g_model, LATENT_DIM)\n",
    "gan.compile(d_optimizer, g_optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1b1d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model.load_weights('./saved_model/d_model85.h5')\n",
    "# g_model.load_weights('./saved_model/g_model85.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4372ebfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 46s 251ms/step - d1_loss: 0.2779 - d2_loss: 0.2402 - g_loss: 3.1686\n",
      "169/169 [==============================] - 6933s 41s/step - d1_loss: 0.2770 - d2_loss: 0.2271 - g_loss: 3.2641\n",
      "169/169 [==============================] - 42s 248ms/step - d1_loss: 0.2861 - d2_loss: 0.2284 - g_loss: 3.4135\n",
      "169/169 [==============================] - 42s 250ms/step - d1_loss: 0.2905 - d2_loss: 0.2295 - g_loss: 3.4657\n",
      "169/169 [==============================] - 42s 249ms/step - d1_loss: 0.2883 - d2_loss: 0.2282 - g_loss: 3.4066\n",
      "169/169 [==============================] - 43s 252ms/step - d1_loss: 0.2877 - d2_loss: 0.2254 - g_loss: 3.4429\n",
      "169/169 [==============================] - 43s 255ms/step - d1_loss: 0.2851 - d2_loss: 0.2256 - g_loss: 3.4960\n",
      "169/169 [==============================] - 43s 252ms/step - d1_loss: 0.3061 - d2_loss: 0.2774 - g_loss: 2.8047\n",
      "169/169 [==============================] - 42s 248ms/step - d1_loss: 0.2848 - d2_loss: 0.2233 - g_loss: 3.1738\n",
      "169/169 [==============================] - 42s 249ms/step - d1_loss: 0.2921 - d2_loss: 0.2245 - g_loss: 3.3154\n",
      "169/169 [==============================] - 41s 245ms/step - d1_loss: 0.2960 - d2_loss: 0.2239 - g_loss: 3.4785\n",
      "169/169 [==============================] - 42s 250ms/step - d1_loss: 0.2956 - d2_loss: 0.2243 - g_loss: 3.4757\n",
      "169/169 [==============================] - 42s 246ms/step - d1_loss: 0.3330 - d2_loss: 0.2374 - g_loss: 3.0060\n",
      "169/169 [==============================] - 42s 248ms/step - d1_loss: 0.2935 - d2_loss: 0.2216 - g_loss: 3.3454\n",
      "169/169 [==============================] - 42s 249ms/step - d1_loss: 0.2951 - d2_loss: 0.2230 - g_loss: 3.4118\n",
      "169/169 [==============================] - 42s 246ms/step - d1_loss: 0.2927 - d2_loss: 0.2250 - g_loss: 3.4588\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2951 - d2_loss: 0.2225 - g_loss: 3.5122\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2887 - d2_loss: 0.2213 - g_loss: 3.4831\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2958 - d2_loss: 0.2232 - g_loss: 3.5463\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.3764 - d2_loss: 0.2514 - g_loss: 3.0782\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2836 - d2_loss: 0.2189 - g_loss: 3.2524\n",
      "169/169 [==============================] - 42s 246ms/step - d1_loss: 0.2919 - d2_loss: 0.2184 - g_loss: 3.4346\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2941 - d2_loss: 0.2205 - g_loss: 3.4604\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2940 - d2_loss: 0.2185 - g_loss: 3.5245\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2968 - d2_loss: 0.2306 - g_loss: 3.2441\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2771 - d2_loss: 0.2158 - g_loss: 3.3298\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2871 - d2_loss: 0.2168 - g_loss: 3.5188\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2888 - d2_loss: 0.2172 - g_loss: 3.5587\n",
      "169/169 [==============================] - 42s 246ms/step - d1_loss: 0.2885 - d2_loss: 0.2181 - g_loss: 3.5049\n",
      "169/169 [==============================] - 42s 246ms/step - d1_loss: 0.2941 - d2_loss: 0.2352 - g_loss: 3.1037\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2786 - d2_loss: 0.2146 - g_loss: 3.4414\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2870 - d2_loss: 0.2164 - g_loss: 3.5975\n",
      "169/169 [==============================] - 42s 246ms/step - d1_loss: 0.2822 - d2_loss: 0.2157 - g_loss: 3.5486\n",
      "169/169 [==============================] - 42s 246ms/step - d1_loss: 0.2831 - d2_loss: 0.2367 - g_loss: 3.1456\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2651 - d2_loss: 0.2119 - g_loss: 3.1955\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2761 - d2_loss: 0.2128 - g_loss: 3.4289\n",
      "169/169 [==============================] - 42s 250ms/step - d1_loss: 0.2761 - d2_loss: 0.2136 - g_loss: 3.5121\n",
      "169/169 [==============================] - 42s 251ms/step - d1_loss: 0.2814 - d2_loss: 0.2158 - g_loss: 3.5390\n",
      "169/169 [==============================] - 42s 250ms/step - d1_loss: 0.2806 - d2_loss: 0.2156 - g_loss: 3.6245\n",
      "169/169 [==============================] - 43s 255ms/step - d1_loss: 0.2875 - d2_loss: 0.2368 - g_loss: 3.2616\n",
      "169/169 [==============================] - 42s 249ms/step - d1_loss: 0.2651 - d2_loss: 0.2118 - g_loss: 3.3542\n",
      "169/169 [==============================] - 42s 248ms/step - d1_loss: 0.2724 - d2_loss: 0.2125 - g_loss: 3.5354\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2744 - d2_loss: 0.2143 - g_loss: 3.6248\n",
      "169/169 [==============================] - 42s 247ms/step - d1_loss: 0.2869 - d2_loss: 0.2222 - g_loss: 3.3554\n",
      "169/169 [==============================] - 42s 249ms/step - d1_loss: 0.2590 - d2_loss: 0.2104 - g_loss: 3.2926\n",
      "169/169 [==============================] - 42s 249ms/step - d1_loss: 0.2707 - d2_loss: 0.2121 - g_loss: 3.5130\n",
      "169/169 [==============================] - 42s 249ms/step - d1_loss: 0.2697 - d2_loss: 0.2134 - g_loss: 3.5318\n",
      "169/169 [==============================] - 42s 250ms/step - d1_loss: 0.2672 - d2_loss: 0.2136 - g_loss: 3.5734\n",
      "169/169 [==============================] - 42s 251ms/step - d1_loss: 0.2847 - d2_loss: 0.2204 - g_loss: 3.2303\n",
      "169/169 [==============================] - 42s 248ms/step - d1_loss: 0.2617 - d2_loss: 0.2103 - g_loss: 3.4692\n"
     ]
    }
   ],
   "source": [
    "n_samples = 25\n",
    "noise = np.random.normal(size = (n_samples, LATENT_DIM))\n",
    "for epoch in range(50):\n",
    "    gan.fit(dataset, epochs = 1)\n",
    "    g_model.save('saved_model/g_model.h5')\n",
    "    d_model.save('saved_model/d_model.h5')\n",
    "    examples = g_model.predict(noise)\n",
    "    save_plot(examples, epoch, int(np.sqrt(n_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5dbd651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in dataset.take(1):\n",
    "#     print(plt.imshow((img[0] + 1)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e8ca3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = g_model(np.random.normal(size = (1,128)))\n",
    "# img = (img+1)/2.0\n",
    "# # img = tf.sigmoid(img)\n",
    "# plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "073a54f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (None, 64, 64, None), types: tf.float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d16c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
